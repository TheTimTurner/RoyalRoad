{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import random\n",
    "#!pip install ProgressBar\n",
    "from progressbar import ProgressBar\n",
    "import math\n",
    "#!{sys.executable} -m pip install ProgressBar\n",
    "#!pip install ProgressBar\n",
    "from random import randrange\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "#svd stuff\n",
    "from scipy.linalg import svd\n",
    "from numpy.linalg import pinv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the titles and wheater the book is alive or dead into two seperate arrays\n",
    "def loadResult():\n",
    "    test_labels = []\n",
    "    test_values = []\n",
    "    with open('table-of-contents.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for books in data:\n",
    "            for book in data[books]:\n",
    "                test_labels.append(book['title'])\n",
    "                test_values.append(book['dead'])\n",
    "                \n",
    "    return test_labels, test_values\n",
    "\n",
    "#get the data from the data output file\n",
    "def loadData():\n",
    "    final_data = []\n",
    "    with open('dataOutput2.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for index in data: \n",
    "            final_data.append(data[index]['chapData'])\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16705\n",
      "Training dataset dimensions:  (15705, 71)\n",
      "Number of training labels:  15705\n",
      "Testing dataset dimensions:  (1000, 71)\n",
      "Number of testing labels:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                \n",
    "\n",
    "title_labels, dead_labels = loadResult()\n",
    "train = loadData()\n",
    "print(len(train))\n",
    "## Load the training set\n",
    "train_data= np.array(train[:15705])\n",
    "train_labels = np.array(dead_labels[:15705])\n",
    "train_titles = np.array(title_labels[:15705])\n",
    "\n",
    "\n",
    "## Load the testing set\n",
    "\n",
    "test_data= np.array(train[-1000:])\n",
    "test_labels = np.array(dead_labels[-1000:])\n",
    "test_titles = np.array(title_labels[-1000:])\n",
    "\n",
    "\n",
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next two items we are attempting to recreating the element. A should equal B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate pseudo inverse manually and compare to the built in version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   1  36]\n",
      " [  0   0   0 ...   0   1   7]\n",
      " [  0   0   0 ...  20  25 689]\n",
      " ...\n",
      " [  0   0   0 ...   1   0   5]\n",
      " [  0   0   0 ...   2   0   1]\n",
      " [  0   0   1 ... 187 255 232]]\n",
      "[[ 1.41665154e-06 -7.87624385e-05 -1.50063288e-05 ... -8.81508881e-05\n",
      "  -2.43381414e-04 -1.57186015e-04]\n",
      " [-3.11887480e-05  4.14462675e-05 -2.39004888e-04 ... -1.38122724e-04\n",
      "  -1.99278900e-05 -3.38553861e-04]\n",
      " [-2.30330965e-05 -3.87923977e-05 -8.42779723e-05 ... -1.93302046e-04\n",
      "  -1.29650184e-05  1.44900618e-03]\n",
      " ...\n",
      " [-3.53724560e-07  4.86100109e-07  1.05452792e-06 ...  6.99338964e-07\n",
      "   5.91041688e-07 -3.66002797e-06]\n",
      " [ 4.49952314e-07 -4.67608076e-07 -1.13338360e-07 ... -6.02837625e-07\n",
      "  -5.32801834e-07  3.21050947e-06]\n",
      " [-3.71539162e-09 -5.57172465e-08  5.07890139e-07 ... -1.54623509e-07\n",
      "  -2.89767954e-08 -2.49413822e-07]]\n"
     ]
    }
   ],
   "source": [
    "#A= np.array([[0.1, 0.2],[0.3, 0.4],[0.5, 0.6],[0.7, 0.8]])\n",
    "A=np.array(train_data[:])\n",
    "print(A)\n",
    "# calculate pseudoinverse\n",
    "B = pinv(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   1  36]\n",
      " [  0   0   0 ...   0   1   7]\n",
      " [  0   0   0 ...  20  25 689]\n",
      " ...\n",
      " [  0   0   0 ...   1   0   5]\n",
      " [  0   0   0 ...   2   0   1]\n",
      " [  0   0   1 ... 187 255 232]]\n",
      "[[ 1.41665154e-06 -7.87624385e-05 -1.50063288e-05 ... -8.81508881e-05\n",
      "  -2.43381414e-04 -1.57186015e-04]\n",
      " [-3.11883520e-05  4.14462206e-05 -2.39004961e-04 ... -1.38122710e-04\n",
      "  -1.99278888e-05 -3.38553853e-04]\n",
      " [-2.30322454e-05 -3.87925141e-05 -8.42781799e-05 ... -1.93302006e-04\n",
      "  -1.29647602e-05  1.44900626e-03]\n",
      " ...\n",
      " [-3.53724719e-07  4.86100125e-07  1.05452794e-06 ...  6.99338961e-07\n",
      "   5.91041740e-07 -3.66002796e-06]\n",
      " [ 4.49952818e-07 -4.67608132e-07 -1.13338439e-07 ... -6.02837610e-07\n",
      "  -5.32801893e-07  3.21050947e-06]\n",
      " [-3.71532570e-09 -5.57172542e-08  5.07890127e-07 ... -1.54623507e-07\n",
      "  -2.89767968e-08 -2.49413821e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "# calculate svd\n",
    "U, s, VT = svd(A)\n",
    "# reciprocals of s\n",
    "d = 1.0 / s\n",
    "# create m x n D matrix\n",
    "D = np.zeros(A.shape)\n",
    "# populate D with n x n diagonal matrix\n",
    "D[:A.shape[1], :A.shape[1]] = np.diag(d)\n",
    "# calculate pseudoinverse\n",
    "B = VT.T.dot(D.T).dot(U.T)\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getError(B):\n",
    "\n",
    "    true = 0\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        x = train_data[i]\n",
    "        predict = np.sum(x.dot(B))\n",
    "\n",
    "        #find the error\n",
    "        if (train_labels[i] == False) and (predict<1):\n",
    "            true +=1\n",
    "        elif (train_labels[i] == True) and (predict>1):\n",
    "            true+=1\n",
    "\n",
    "\n",
    "\n",
    "        #these are  the results from the svd classification\n",
    "        #print(predict, end = \": \")\n",
    "        #print(train_labels[i])\n",
    "\n",
    "        #calculate the error\n",
    "\n",
    "    #print('error rate: ', 1-(true/len(train_data)))\n",
    "    return 1-(true/len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate:  0.3444126074498567\n"
     ]
    }
   ],
   "source": [
    "print('error rate: ', getError(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the derivative of the regression cost function: \n",
    "$$L_D(w) = \\frac{1}{n}\\sum_{i=1}^n (y_i-w\\cdot x_i)^2,$$\n",
    "where $x_i\\in \\mathrm{R}^d$ is the input feature of dimension $d$, $y_i\\in\\mathrm{R}$ is the output response, and $w\\in\\mathrm{R}^d$ is the regression weights.\n",
    "\n",
    "**Task P3:** Complete the function 'weight_derivative' to calculate the derivative of the cost function with respect to regression weights $w$, i.e., $\\frac{\\partial}{\\partial w}L_D(w)$. Note that this should be a $d$ dimensional vector. Also copy the output of the code for the test example to the solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_derivative(weights, feature_matrix, labels):\n",
    "    # Input:\n",
    "    # weights: weight vector w, a numpy vector of dimension d\n",
    "    # feature_matrix: numpy array of size n by d, where n is the number of data points, and d is the feature dimension\n",
    "    # labels: true labels y, a numpy vector of dimension d\n",
    "    # Output:\n",
    "    # Derivative of the regression cost function with respect to the weight w, a numpy array of dimension d\n",
    "        \n",
    "    ## STUDENT: Start of code ###\n",
    "    \n",
    "    sum = 0\n",
    "    #get array of normalized dot produts\n",
    "    dot_product=predict_output(feature_matrix,weights)\n",
    "    #sum the diffrence between dot and true value\n",
    "    for i in range(len(feature_matrix)):\n",
    "        \n",
    "        diffrence = labels[i] - dot_product[i]\n",
    "        sum = sum + diffrence\n",
    "    #finsh derive ative of regressive cost function    \n",
    "    return sum/(len(feature_matrix))*2\n",
    "    # End of code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2ecf53b5aff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmy_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this makes all the predictions 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mderivative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mderivative\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example_features' is not defined"
     ]
    }
   ],
   "source": [
    "# NOTE: copy the output to the solution file.\n",
    "\n",
    "\n",
    "\n",
    "my_weights = np.zeros(len(train_data[0])) # this makes all the predictions 0\n",
    "derivative = weight_derivative(my_weights, example_features,example_output)\n",
    "\n",
    "print (derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
