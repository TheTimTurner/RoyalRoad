{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revelvent infor has come so far from https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import random\n",
    "#!pip install ProgressBar\n",
    "from progressbar import ProgressBar\n",
    "import math\n",
    "#!{sys.executable} -m pip install ProgressBar\n",
    "#!pip install ProgressBar\n",
    "from random import randrange\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "#svd stuff\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the titles and wheater the book is alive or dead into two seperate arrays\n",
    "def loadResult():\n",
    "    test_labels = []\n",
    "    test_values = []\n",
    "    with open('table-of-contents.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for books in data:\n",
    "            for book in data[books]:\n",
    "                test_labels.append(book['title'])\n",
    "                test_values.append(book['dead'])\n",
    "                \n",
    "    return test_labels, test_values\n",
    "\n",
    "#get the data from the data output file\n",
    "def loadData():\n",
    "    final_data = []\n",
    "    with open('dataOutput2.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for index in data: \n",
    "            final_data.append(data[index]['chapData'][:-2])\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16705\n",
      "Training dataset dimensions:  (15705, 69)\n",
      "Number of training labels:  15705\n",
      "Testing dataset dimensions:  (1000, 69)\n",
      "Number of testing labels:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                \n",
    "\n",
    "title_labels, dead_labels = loadResult()\n",
    "train = loadData()\n",
    "print(len(train))\n",
    "## Load the training set\n",
    "train_data= np.array(train[:15705])\n",
    "train_labels = np.array(dead_labels[:15705])\n",
    "train_titles = np.array(title_labels[:15705])\n",
    "\n",
    "\n",
    "## Load the testing set\n",
    "\n",
    "test_data= np.array(train[-1000:])\n",
    "test_labels = np.array(dead_labels[-1000:])\n",
    "test_titles = np.array(title_labels[-1000:])\n",
    "\n",
    "\n",
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  849    2    0]\n",
      " [   0    0    0 ...  336    0    0]\n",
      " [   0    0    0 ...  417   70   20]\n",
      " ...\n",
      " [   0    0    0 ...  144    1    1]\n",
      " [   0    0    0 ...  460    6    2]\n",
      " [   0    0    1 ... 2975  827  187]]\n",
      "[[ 1.05614905e-06 -7.79004242e-05 -1.90625305e-05 ... -8.63623163e-05\n",
      "  -2.42681506e-04 -1.57934874e-04]\n",
      " [-3.09073299e-05  4.24658568e-05 -2.50240039e-04 ... -1.34984985e-04\n",
      "  -1.95261048e-05 -3.31637044e-04]\n",
      " [-2.38074304e-05 -3.68791095e-05 -9.35157743e-05 ... -1.89294921e-04\n",
      "  -1.14270771e-05  1.44762869e-03]\n",
      " ...\n",
      " [ 2.04468186e-09 -7.12800011e-09 -1.13495392e-08 ... -2.63635122e-08\n",
      "  -9.21545881e-09 -4.40159162e-09]\n",
      " [ 2.54053193e-08 -9.56012492e-08 -1.85223121e-07 ... -1.35488598e-07\n",
      "  -1.32083093e-07  9.71013994e-07]\n",
      " [-1.43653194e-07  3.33292756e-07  4.44212104e-07 ...  5.93372467e-07\n",
      "   3.78987532e-07 -1.91603752e-06]]\n"
     ]
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(1,20):\n",
    "\t\tsteps = [('svd', TruncatedSVD(n_components=i)), ('m', LogisticRegression())]\n",
    "\t\tmodels[str(i)] = Pipeline(steps=steps)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  849    2    0]\n",
      " [   0    0    0 ...  336    0    0]\n",
      " [   0    0    0 ...  417   70   20]\n",
      " ...\n",
      " [   0    0    0 ...  144    1    1]\n",
      " [   0    0    0 ...  460    6    2]\n",
      " [   0    0    1 ... 2975  827  187]]\n",
      "[[ 1.05614905e-06 -7.79004242e-05 -1.90625305e-05 ... -8.63623163e-05\n",
      "  -2.42681506e-04 -1.57934874e-04]\n",
      " [-3.09075371e-05  4.24658840e-05 -2.50239993e-04 ... -1.34984993e-04\n",
      "  -1.95261458e-05 -3.31637058e-04]\n",
      " [-2.38065923e-05 -3.68792182e-05 -9.35159541e-05 ... -1.89294888e-04\n",
      "  -1.14269327e-05  1.44762874e-03]\n",
      " ...\n",
      " [ 2.04468621e-09 -7.12800073e-09 -1.13495403e-08 ... -2.63635120e-08\n",
      "  -9.21545714e-09 -4.40159113e-09]\n",
      " [ 2.54053512e-08 -9.56012530e-08 -1.85223127e-07 ... -1.35488597e-07\n",
      "  -1.32083092e-07  9.71013994e-07]\n",
      " [-1.43653429e-07  3.33292787e-07  4.44212156e-07 ...  5.93372457e-07\n",
      "   3.78987486e-07 -1.91603753e-06]]\n",
      "1083645\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "# calculate svd\n",
    "U, s, VT = svd(A)\n",
    "# reciprocals of s\n",
    "d = 1.0 / s\n",
    "# create m x n D matrix\n",
    "D = np.zeros(A.shape)\n",
    "# populate D with n x n diagonal matrix\n",
    "D[:A.shape[1], :A.shape[1]] = np.diag(d)\n",
    "# calculate pseudoinverse\n",
    "B = VT.T.dot(D.T).dot(U.T)\n",
    "print(B)\n",
    "print(B.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
