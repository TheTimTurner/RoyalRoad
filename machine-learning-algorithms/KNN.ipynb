{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming assignment 2: KNN classifier\n",
    "\n",
    "In this programming exercise, we will build a KNN classifier and apply it to a handwritten digit dataset (MNIST). Please download the datasets from Canvas and put them in the same folder of this iPython notebook.\n",
    "\n",
    "Instructions for submission: please submit the following:\n",
    "* Completed iPython notebook. We will inspect the code and run your notebook.\n",
    "* Solutions to the corresponding problems\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The MNIST dataset\n",
    "\n",
    "`MNIST` is a classic database of handwritten digits that is commonly used for training various image processing systems. The MNIST database contains 60,000 training images and 10,000 testing images. In this notebook we will work with a subset of this data: a training set of 2,000 images and a test set of 500 images. Each image is given by 28 X 28 grayscale pixels.\n",
    "\n",
    "First, let's first load the dataset check the basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import random\n",
    "#!pip install ProgressBar\n",
    "from progressbar import ProgressBar\n",
    "import math\n",
    "#!{sys.executable} -m pip install ProgressBar\n",
    "#!pip install ProgressBar\n",
    "from random import randrange\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import glob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the titles and wheater the book is alive or dead into two seperate arrays\n",
    "def loadResult():\n",
    "    test_labels = []\n",
    "    test_values = []\n",
    "    with open('table-of-contents.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for books in data:\n",
    "            for book in data[books]:\n",
    "                test_labels.append(book['title'])\n",
    "                test_values.append(book['dead'])\n",
    "                \n",
    "    return test_labels, test_values\n",
    "\n",
    "#get the data from the data output file\n",
    "def loadData():\n",
    "    final_data = []\n",
    "    with open('dataOutput2.json', encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "        for index in data: \n",
    "            final_data.append(data[index]['chapData'])\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16705\n",
      "Training dataset dimensions:  (15705, 71)\n",
      "Number of training labels:  15705\n",
      "Testing dataset dimensions:  (1000, 71)\n",
      "Number of testing labels:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                \n",
    "\n",
    "title_labels, dead_labels = loadResult()\n",
    "train = loadData()\n",
    "print(len(train))\n",
    "## Load the training set\n",
    "train_data= np.array(train[:15705])\n",
    "train_labels = np.array(dead_labels[:15705])\n",
    "train_titles = np.array(title_labels[:15705])\n",
    "\n",
    "\n",
    "## Load the testing set\n",
    "\n",
    "test_data= np.array(train[-1000:])\n",
    "test_labels = np.array(dead_labels[-1000:])\n",
    "test_titles = np.array(title_labels[-1000:])\n",
    "\n",
    "\n",
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's randomly choose 10 images from the training dataset and visualize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN based on Euclidean distance\n",
    "\n",
    "Let's first experiment with _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "**Task P1:** Complete the following code section to calculate this distance. Copy the corresponding code to the problem set 1 solution pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes squared Euclidean distance between two vectors.\n",
    "def eucl_dist(x,y):\n",
    "    # input:\n",
    "    # x, y: vectorization of an image\n",
    "    # output:\n",
    "    # the euclidean distance between the two vectors\n",
    "    \n",
    "    ### STUDENT: YOUR CODE HERE\n",
    "    \n",
    "    d = len(x)\n",
    "    sum = 0\n",
    "    \n",
    "    for i in range(d):  \n",
    "        sum = sum + pow((x[i]-y[i]),2)\n",
    "    \n",
    "    sum = math.sqrt(abs(sum)) \n",
    "    return sum\n",
    "### CODE ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to compute the distance between some randomly chosen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from Forgotten Pages to Ha Ha... Love Triangle. No.: 770.686706775198\n",
      "Distance from Eternal War to Linked Darkness: 13693.42338496842\n",
      "Distance from Forsaken Realms to Operation Abaddon: 44182.57267294425\n",
      "Distance from Happiness System to Nirwana: 1006.474540164827\n",
      "Distance from Nero, My Existence is Perfect to Dungeon core: 32459.904235841484\n"
     ]
    }
   ],
   "source": [
    "index = random.sample(range(len(train_labels)), 10)\n",
    "for i in range(5):\n",
    "    # Image index\n",
    "    k = i * 2\n",
    "    \n",
    "    print(\"Distance from \"+str(train_titles[index[k]])+\" to \"+str(train_titles[index[k+1]])+\": \"+\n",
    "          str(eucl_dist(train_data[index[k],],train_data[index[k+1],])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement the K-nearest neighbor classification. \n",
    "\n",
    "**Task P2:** Complete the following code sections for `find_KNN` and `KNN_classifier`. Copy the corresponding code to the problem set 1 solution pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a vector x and returns the indices of its K nearest neighbors in the training set: train_data\n",
    "def find_KNN(x, train_data, train_labels, K, dist=eucl_dist):\n",
    "    # Input: \n",
    "    # x: test point\n",
    "    # train_data: training data X\n",
    "    # train_labels: training data labels y\n",
    "    # K: number of nearest neighbors considered\n",
    "    # dist: default to be the eucl_dist that you have defined above\n",
    "    # Output:\n",
    "    # The indices of the K nearest neighbors to test point x in the training set\n",
    "    \n",
    "    ##### STUDENT: Your code here #####\n",
    "    #list of distances from x\n",
    "    distances = list()\n",
    "    index = 0;\n",
    "    #go through the training data\n",
    "    for train_row in train_data:\n",
    "        curr_dist=dist(train_row, x)\n",
    "        #all the distances\n",
    "        distances.append((index, curr_dist))\n",
    "        index=index+1\n",
    "    #sort    \n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "   # return the lowest K distances\n",
    "    for i in range(K):\n",
    "        \n",
    "        neighbors.append(distances[i][0])\n",
    "    \n",
    "    return neighbors\n",
    "    ##### END OF CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should make use of the `find_KKN` function to define the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classification\n",
    "def KNN_classifier(x, train_data, train_labels,K,dist=eucl_dist):\n",
    "    # Input:\n",
    "    # x: test point\n",
    "    # train_data: training data X\n",
    "    # train_labels: training data labels y\n",
    "    # K: number of nearest neighbors considered\n",
    "    # dist: default to be the eucl_dist that you have defined above\n",
    "    # Output:\n",
    "    # the predicted label of the test point\n",
    "    \n",
    "    ##### STUDENT: Your code here #####\n",
    "   \n",
    "    #get the lowest K neighbors\n",
    "    neighbors = find_KNN(x, train_data, train_labels,K,dist)\n",
    "     \n",
    "    if K is 1:\n",
    "        # return the only label\n",
    "        return train_labels[neighbors[0]]\n",
    "    else:\n",
    "        #value will be teh amount of times an number appears by index\n",
    "        value = [0]*10\n",
    "        #find the max alue of an item\n",
    "        max =0;\n",
    "        index = 0;\n",
    "        #find the average of classification between K objects returned from find_KNN\n",
    "        for item in neighbors:\n",
    "            value[train_labels[item]]=value[train_labels[item]]+1\n",
    "        #find the number that appeared most often and return it\n",
    "        for i in range(10):\n",
    "            if value[i]>max:\n",
    "                max = value[i]\n",
    "                index = i\n",
    "        return index\n",
    "    ##### END OF CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine how the code works for 1-NN (i.e., with K=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P3: Find one example of success case and one example of failed case for 1-NN. Print the outputs and copy them to the problem set solution file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A success case:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in long_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN classification:  True\n",
      "True label:  True\n",
      "The test image:\n",
      "5\n",
      "The corresponding nearest neighbor image:\n",
      "A failure case:\n",
      "NN classification:  True\n",
      "True label:  True\n",
      "The test image:\n",
      "The corresponding nearest neighbor image:\n"
     ]
    }
   ],
   "source": [
    "## A success case:\n",
    "ind_success =  5 ### STUDENT: put one index of a success case here\n",
    "#print(type(ind_success))\n",
    "print(\"A success case:\")\n",
    "print(\"1-NN classification: \", KNN_classifier(test_data[ind_success,],train_data,train_labels,1,eucl_dist))\n",
    "print(\"True label: \", test_labels[ind_success])\n",
    "print(\"The test image:\")\n",
    "print(ind_success)\n",
    "#vis_image(ind_success, \"test\")\n",
    "print(\"The corresponding nearest neighbor image:\")\n",
    "#vis_image(find_KNN(test_data[ind_success,],train_data,train_labels,1,eucl_dist)[0], \"train\")\n",
    "\n",
    "## A failure case:\n",
    "ind_fail =  24 ### STUDENT: put one index of a failued case here\n",
    "print(\"A failure case:\")\n",
    "print(\"NN classification: \", KNN_classifier(test_data[ind_fail,],train_data,train_labels,1,eucl_dist))\n",
    "print(\"True label: \", test_labels[ind_fail])\n",
    "print(\"The test image:\")\n",
    "#vis_image(ind_fail, \"test\")\n",
    "print(\"The corresponding nearest neighbor image:\")\n",
    "#vis_image(find_KNN(test_data[ind_fail,],train_data,train_labels,1,eucl_dist)[0], \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply our K-nearest neighbor classifier over the full data set with `K=3`. \n",
    "\n",
    "Note that to classify each test point, our code takes a full pass over each of the 2000 training examples. The following code takes about 8 seconds on 3.3 GHz Intel Core i. \n",
    "\n",
    "**Task P4: Report the outputs of the following code and copy them to the problem set solution file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in long_scalars\n",
      "  \n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with Euclidean distance:  0.203\n",
      "Classification time (seconds) with Euclidean distance:  2153.537331342697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict on each test data point (and time it!)\n",
    "pbar = ProgressBar() # to show progress\n",
    "t_before = time.time()\n",
    "test_predictions = np.zeros(len(test_labels))\n",
    "for i in pbar(range(len(test_labels))):   \n",
    "    test_predictions[i] = KNN_classifier(test_data[i,],train_data,train_labels,1,eucl_dist)\n",
    "    \n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the error\n",
    "err_positions = np.not_equal(test_predictions, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print(\"Error of nearest neighbor classifier with Euclidean distance: \", error)\n",
    "print(\"Classification time (seconds) with Euclidean distance: \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Different distance metrics\n",
    "\n",
    "So far, we have been using the Euclidean distance. In this section, let's try the Manhattan distance. You will also design a distance function and report the results.\n",
    "\n",
    "Recall that the Manhattan distance (a.k.a. $\\ell_1$-norm) is given by:\n",
    "$$\\|x - y\\|_1 = {\\sum_{i=1}^d |x_i - y_i|}.$$\n",
    "\n",
    "**Task P5: Complete the definition of `manh_dist` and report the outputs of the following code and copy them to the problem set solution file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with Manhattan distance:  0.14\n",
      "Classification time (seconds) with Manhattan distance:  1866.8594551086426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Computes Manhattan distance between two vectors.\n",
    "def manh_dist(x,y):\n",
    "    # input:\n",
    "    # x, y: vectorization of an image of size 28 by 28\n",
    "    # output:\n",
    "    # the distance between the two vectors\n",
    "    \n",
    "    ### STUDENT: YOUR CODE HERE\n",
    "    d = len(x)\n",
    "    sum = 0.0\n",
    "    \n",
    "    for i in range(d):\n",
    "        sum = sum + abs(x[i]-y[i])\n",
    "\n",
    "    return sum\n",
    "    ### CODE ENDS\n",
    "\n",
    "pbar = ProgressBar() # to show progress\n",
    "## Predict on each test data point (and time it!)\n",
    "t_before = time.time()\n",
    "test_predictions = np.zeros(len(test_labels))\n",
    "for i in pbar(range(len(test_labels))):   \n",
    "    test_predictions[i] = KNN_classifier(test_data[i,],train_data,train_labels,3,manh_dist)\n",
    "    \n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the error\n",
    "err_positions = np.not_equal(test_predictions, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print(\"Error of nearest neighbor classifier with Manhattan distance: \", error)\n",
    "print(\"Classification time (seconds) with Manhattan distance: \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P6: Define your own distance function and write down the mathematical definition. Copy the code and the result to the problem set solution file. (2 bonus point) Can you improve over the Euclidean distance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute a distance metric of your design\n",
    "def my_dist(x,y):\n",
    "    # input:\n",
    "    # x, y: vectorization of an image of size 28 by 28 \n",
    "    # output:\n",
    "    # the distance between the two vectors\n",
    "    \n",
    "    ### STUDENT: YOUR CODE HERE\n",
    "    #get the lenght of x and y\n",
    "    \n",
    "    #Squared chord distance (SCD)\n",
    "    #we take the square root of each point,\n",
    "    #find the diffrence and square that diffrence\n",
    "    \n",
    "    sum = 0.0\n",
    "\n",
    "    d = len(x)\n",
    "    \n",
    "    for i in range(d):\n",
    "        diff = abs(math.sqrt(x[i]))-abs(math.sqrt(y[i]))\n",
    "        sum = sum +pow(diff,2)\n",
    "    \n",
    "    return sum\n",
    "    ### CODE ENDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.135\n",
      "Classification time (seconds) with the new distance:  1476.267017364502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar() # to show progress\n",
    "## Predict on each test data point (and time it!)\n",
    "t_before = time.time()\n",
    "test_predictions = np.zeros(len(test_labels))\n",
    "for i in pbar(range(len(test_labels))):   \n",
    "    test_predictions[i] = KNN_classifier(test_data[i,],train_data,train_labels,3,my_dist)\n",
    "\n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the error\n",
    "err_positions = np.not_equal(test_predictions, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print(\"Error of nearest neighbor classifier with the new distance: \", error)\n",
    "print(\"Classification time (seconds) with the new distance: \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validation to select K\n",
    "\n",
    "k-Fold Cross Validation (don't confuse this k with the K in KNN!) is a very useful technique to check how well a model performs when we apply it on an independent data. It is often used to flag problems caused by overfitting and selection bias. However, it brings an additional data processing load and time.\n",
    "\n",
    "<img style=\"width:500px\" src=\"K-fold-CV.png\">\n",
    "\n",
    "**Task P7: Implement the 5-fold cross validation to choose the best K (number of nearest neighbors) between 1 and 10 for KNN with Euclidean distance. Copy the code in the solution file and plot the 5-fold validation error with respect to K. Also plot the test error on the same figure. What do you observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in long_scalars\n",
      "  \n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.93\n",
      "Classification time (seconds) with the new distance:  428.66893553733826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.205\n",
      "Classification time (seconds) with the new distance:  437.8817894458771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.35\n",
      "Classification time (seconds) with the new distance:  437.47042059898376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.135\n",
      "Classification time (seconds) with the new distance:  436.2190523147583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of nearest neighbor classifier with the new distance:  0.175\n",
      "Classification time (seconds) with the new distance:  423.97146010398865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### STUDENT: YOUR CODE HERE\n",
    "\n",
    "# Split a dataset and solutions into k folds\n",
    "dataset_split = list()\n",
    "dataset_copy = deepcopy(test_data)\n",
    "labels_split = list()\n",
    "labels_copy = list(test_labels)\n",
    "#get the size each fold should be\n",
    "fold_size = int(len(test_data) / 5)\n",
    "\n",
    "#print(dataset_copy[0])\n",
    "\n",
    "curr_index = 0\n",
    "for i in range(5):\n",
    "    \n",
    "    fold = []\n",
    "    solutions = list()\n",
    "    \n",
    "    while len(solutions) < fold_size:\n",
    "    #palce a random index into the return list\n",
    "        index = randrange(len(labels_copy))\n",
    "        \n",
    "        fold.append(dataset_copy[index])\n",
    "        dataset_copy = np.delete(dataset_copy,index,0)\n",
    "        solutions.append(labels_copy.pop(index))\n",
    "        curr_index +=1 \n",
    "        \n",
    "    #print(len(dataset_copy))\n",
    "    #print(len(solutions))\n",
    "    #print(fold)\n",
    "    dataset_split.append(fold)\n",
    "    labels_split.append(solutions)\n",
    "\n",
    "\n",
    "curr_fold = 0\n",
    "k_value = 1\n",
    "for fold in dataset_split:\n",
    "    pbar = ProgressBar() # to show progress\n",
    "    ## Predict on each test data point (and time it!)\n",
    "    t_before = time.time()\n",
    "    \n",
    "    test_predictions = np.zeros(len(labels_split[0]))\n",
    "    #print(dataset_split[0][0])\n",
    "    for i in pbar(range(len(labels_split[0]))): \n",
    "        #print(test_data[i,])\n",
    "        #print(dataset_split[i,])\n",
    "        #print(labels_split[i])\n",
    "        \n",
    "        test_predictions[i] = KNN_classifier(fold[i],train_data,train_labels,curr_fold,eucl_dist)\n",
    "\n",
    "    t_after = time.time()\n",
    "\n",
    "    ## Compute the error\n",
    "    err_positions = np.not_equal(test_predictions, labels_split[curr_fold])\n",
    "    error = float(np.sum(err_positions))/len(labels_split[curr_fold])\n",
    "\n",
    "    print(\"Error of nearest neighbor classifier with the new distance: \", error)\n",
    "    print(\"Classification time (seconds) with the new distance: \", t_after - t_before)\n",
    "    curr_fold = curr_fold+1\n",
    "    k_value = k_value +2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just implemented the KNN algorithm and tested it on the MNIST dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
